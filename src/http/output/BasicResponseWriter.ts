import { getLoggerFor } from '../../logging/LogUtil';
import { HttpRequest } from '../../server/HttpRequest';
import type { HttpResponse } from '../../server/HttpResponse';
import { isInternalContentType } from '../../storage/conversion/ConversionUtil';
import { NotImplementedHttpError } from '../../util/errors/NotImplementedHttpError';
import { pipeSafely } from '../../util/StreamUtil';
import type { MetadataWriter } from './metadata/MetadataWriter';
import type { ResponseDescription } from './response/ResponseDescription';
import { ResponseWriter } from './ResponseWriter';
import { BadRequestHttpError } from '../../util/errors/BadRequestHttpError';
import { BasicRepresentation } from '../representation/BasicRepresentation';
import { Guarded, guardStream } from '../../util/GuardedStream';
import { PassThrough, Readable } from 'node:stream';
import { OkResponseDescription } from './response/OkResponseDescription';
import { RepresentationMetadata } from '../representation/RepresentationMetadata';
import { addHeader } from '../../index';


// TOOD: use local variable now.. use a store instead ?
// Subscription storage: keys are generated by subscription_hash
const subscriptions: { [key: string]: any } = {};

// Generate a subscription key using the input.request's peer header and url
const subscription_hash = (req: any): string =>
  JSON.stringify([req.headers.peer, req.url]);

// TODO interface should be put somewhere else
export type BraidHttpRequest = HttpRequest & {
  subscribe?: boolean;
  patches?: any;
}

export type BraidHttpResponse = HttpResponse & {
  sendUpdate?: (update: { version: string[], body: string }) => void;
  startSubscription?: any;
}


/**
 * Writes to an {@link HttpResponse} based on the incoming {@link ResponseDescription}.
 */
export class BasicResponseWriter extends ResponseWriter {
  protected readonly logger = getLoggerFor(this);
  private readonly metadataWriter: MetadataWriter;

  public constructor(metadataWriter: MetadataWriter) {
    super();
    this.metadataWriter = metadataWriter;
  }

  public async canHandle(input: { response: BraidHttpResponse; request?: BraidHttpRequest; result: ResponseDescription }): Promise<void> {
    const contentType = input.result.metadata?.contentType;
    if (isInternalContentType(contentType)) {
      throw new NotImplementedHttpError(`Cannot serialize the internal content type ${contentType}`);
    }
  }


  // TODO not use any but extends HTTPRequest with BraidHTTPRequest
  public async handle(input: { response: BraidHttpResponse; request?: BraidHttpRequest; result: ResponseDescription }): Promise<void> {
    if (input.result.metadata) {
      await this.metadataWriter.handleSafe({ response: input.response, metadata: input.result.metadata });

    }


    // BRAID
    // If the request is a subscription, start it and store the response
    if (input.request && input.request.headers.peer && input.request.method == "GET") {

      // weirdly I had to add that to make it work. It was included the response header
      // in `braidjs` branch but not in that one. I don't what create them, but it seems 
      // not to work without, so I'm adding them manually. 
      // in braid-http-server there is comment l.531 stating that chunked enconding means
      // the end of a response and we should not use them, so I'm puzzled
       
      addHeader(input.response, 'Transfer-Encoding', 'chunked')

      if (input.request.subscribe) {
        input.response.startSubscription({
          onClose: async () => {

            delete subscriptions[subscription_hash(input.request)];
            // await this.braidStore.delete(subscription_hash(input.request))
            this.logger.info(`Subscription closed for hash ${subscription_hash(input.request)}`);
          }
        });
        subscriptions[subscription_hash(input.request)] = input.response;
        // await this.braidStore.set(subscription_hash(input.request), input.response);
        this.logger.info(`Subscribing at hash ${subscription_hash(input.request)}`);
      } else {
        // it was in the example but doesn't seems to be useful
        input.response.statusCode = 200;
      }


      // Send the current data as the update payload
      if (input.response.sendUpdate) {
        // const eTag = this.eTagHandler.getETag(body.metadata);
        // updateVersion = eTag
        let updateVersion = Math.random().toString().slice(2, 8)
        let content;
        // Clone the stream before reading
        // Ensure stream is in flowing mode and collect data
        if (!input.result.data) return
        content = await readableToBuffer(input.result.data);
        content = content.toString();

        input.response.sendUpdate({
          version: [updateVersion],
          body: JSON.stringify([{ text: content }])
        });


      }

      // I feel we don't need the following anymore:

      // Properly handle input.response ending based on input.request type
      // if (!input.request.subscribe) {
      //   return new OkResponseDescription(body.metadata, dataStream2);
      // } else {
      if ( input.request.subscribe){
        // I need to keep the HTTP connection open
        // let's create a stream and not close it
        // idk if this the right way, but no other idea for now
        const stream = guardStream(new PassThrough())
        // this.streamMap.add(topic, stream);
        stream.on('error', () => {
          this.logger.warn(">>>>>>>>> STREAM ERROR")
        });
        stream.on('close', () => {
          this.logger.warn(">>>>>>>>> STREAM CLOSED")
        });
        // input.result.data = stream
        const metadata = input.result.metadata || new RepresentationMetadata()
        input.result =  new OkResponseDescription(metadata , stream)
      }

    }

    if (input.request && input.request.headers.peer && input.request.method == "PUT") {
      // Broadcast the update to all subscribers for this URL, excluding the sender
      if (input.request.headers.peer) {
        for (const key in subscriptions) { // TODO how to iterate over subscription ??

          
          let content = ''
          if (input.result.data){

            input.result.data.resume();
            content = (await readableToBuffer(input.result.data)).toString();
          }
          // else trigger error ?

          try {
            const [peer, url] = JSON.parse(key);
            // let relativePath = operation.target.path.replace('http://localhost:3000', '') // TODO dynamically
            // if (url === relativePath && peer !== input.request.headers.peer) {
            if (url === input.request.url) {
              // let sub = await this.braidStore.get(key)
              let sub = subscriptions[key]
              let updateVersion = Math.random().toString().slice(2, 8)
              sub.sendUpdate({
                version: [updateVersion],
                // let's just send the content we got from the patch form now
                // later, we will need to apply the patches first and get the content. 
                // and we should get the content from the representation ( freshly patched )
                body: JSON.stringify([{ text: content }]) // TODO get content
              });

              input.response.end()
              return 
            }
          } catch (err) {
            this.logger.error('Error parsing subscription key:' + err);
          }
        }
      }
    }


    // END BRAID


    // debug: remove me
    if (!input.response.headersSent)
      input.response.writeHead(input.result.statusCode);

    if (input.result.data) {
      const pipe = pipeSafely(input.result.data, input.response);
      pipe.on('error', (error): void => {
        this.logger.error(`Aborting streaming response because of server error; headers already sent.`);
        this.logger.error(`Response error: ${error.message}`);
      });
    } else {
      // If there is input data the response will end once the input stream ends
      input.response.end();
    }
  }
}
/** Helper to collect stream data into a Buffer */
async function readableToBuffer(stream: Guarded<Readable>): Promise<Buffer> {
  return new Promise((resolve, reject) => {
    const chunks: Buffer[] = [];
    stream.on('data', (chunk: any) => chunks.push(chunk));
    stream.on('end', () => resolve(Buffer.concat(chunks)));
    stream.on('error', reject);
  });
}